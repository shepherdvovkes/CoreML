#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Ollama —Å–µ—Ä–≤–µ—Ä—É –Ω–∞ localhost
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å API –∏ —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
"""
import asyncio
import httpx
import json
from typing import Optional


async def check_ollama_server(base_url: str = "http://localhost:11434", timeout: float = 5.0) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ Ollama —Å–µ—Ä–≤–µ—Ä–∞"""
    print(f"üîç –ü—Ä–æ–≤–µ—Ä—è—é Ollama —Å–µ—Ä–≤–µ—Ä –Ω–∞ {base_url}...")
    
    try:
        async with httpx.AsyncClient(timeout=timeout) as client:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–∑–æ–≤—ã–π endpoint
            response = await client.get(f"{base_url}/api/tags")
            
            if response.status_code == 200:
                data = response.json()
                models = data.get("models", [])
                print(f"‚úÖ Ollama —Å–µ—Ä–≤–µ—Ä –¥–æ—Å—Ç—É–ø–µ–Ω!")
                print(f"   –î–æ—Å—Ç—É–ø–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(models)}")
                
                if models:
                    print(f"\nüìã –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π:")
                    for model in models[:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
                        name = model.get("name", "unknown")
                        size = model.get("size", 0)
                        size_gb = size / (1024**3) if size > 0 else 0
                        modified = model.get("modified_at", "")
                        print(f"   ‚Ä¢ {name}")
                        if size_gb > 0:
                            print(f"     –†–∞–∑–º–µ—Ä: {size_gb:.2f} GB")
                        if modified:
                            print(f"     –û–±–Ω–æ–≤–ª–µ–Ω–æ: {modified}")
                else:
                    print(f"   ‚ö†Ô∏è  –ú–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –º–æ–¥–µ–ª—å:")
                    print(f"      ollama pull llama2")
                
                return True
            else:
                print(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Å—Ç–∞—Ç—É—Å: {response.status_code}")
                print(f"   –û—Ç–≤–µ—Ç: {response.text[:200]}")
                return False
                
    except httpx.TimeoutException:
        print(f"‚ùå –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–∏ –∫ {base_url}")
        print(f"   –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ Ollama —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω:")
        print(f"   ollama serve")
        return False
    except httpx.ConnectError:
        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ {base_url}")
        print(f"   –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ Ollama —Å–µ—Ä–≤–µ—Ä –∑–∞–ø—É—â–µ–Ω:")
        print(f"   ollama serve")
        return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        return False


async def test_ollama_generate(base_url: str = "http://localhost:11434", model: str = "llama2", timeout: float = 30.0) -> bool:
    """–¢–µ—Å—Ç –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ Ollama API"""
    print(f"\nüí¨ –¢–µ—Å—Ç–∏—Ä—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å '{model}'...")
    
    try:
        async with httpx.AsyncClient(timeout=timeout) as client:
            response = await client.post(
                f"{base_url}/api/generate",
                json={
                    "model": model,
                    "prompt": "Say 'OK' if you can read this.",
                    "stream": False
                }
            )
            
            if response.status_code == 200:
                data = response.json()
                response_text = data.get("response", "")
                print(f"‚úÖ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞!")
                print(f"   –û—Ç–≤–µ—Ç: {response_text.strip()}")
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                if "eval_count" in data:
                    print(f"   –¢–æ–∫–µ–Ω–æ–≤ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ: {data.get('eval_count', 0)}")
                if "total_duration" in data:
                    duration = data.get("total_duration", 0) / 1e9  # –Ω–∞–Ω–æ—Å–µ–∫—É–Ω–¥—ã –≤ —Å–µ–∫—É–Ω–¥—ã
                    print(f"   –í—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {duration:.2f} —Å–µ–∫")
                
                return True
            elif response.status_code == 404:
                print(f"‚ùå –ú–æ–¥–µ–ª—å '{model}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                print(f"   –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –º–æ–¥–µ–ª—å:")
                print(f"   ollama pull {model}")
                return False
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞: {response.status_code}")
                print(f"   {response.text[:200]}")
                return False
                
    except httpx.TimeoutException:
        print(f"‚ùå –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (>{timeout} —Å–µ–∫)")
        print(f"   –ú–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ª–∏—à–∫–æ–º –º–µ–¥–ª–µ–Ω–Ω–æ–π –∏–ª–∏ –±–æ–ª—å—à–æ–π")
        return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
        return False


async def test_ollama_stream(base_url: str = "http://localhost:11434", model: str = "llama2", timeout: float = 30.0) -> bool:
    """–¢–µ—Å—Ç –ø–æ—Ç–æ–∫–æ–≤–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ Ollama API"""
    print(f"\nüåä –¢–µ—Å—Ç–∏—Ä—É—é –ø–æ—Ç–æ–∫–æ–≤—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å '{model}'...")
    
    try:
        async with httpx.AsyncClient(timeout=timeout) as client:
            async with client.stream(
                "POST",
                f"{base_url}/api/generate",
                json={
                    "model": model,
                    "prompt": "Count from 1 to 5.",
                    "stream": True
                }
            ) as response:
                if response.status_code == 200:
                    chunks = []
                    async for line in response.aiter_lines():
                        if line:
                            try:
                                data = json.loads(line)
                                if "response" in data:
                                    chunk = data["response"]
                                    chunks.append(chunk)
                                    print(chunk, end="", flush=True)
                                if data.get("done", False):
                                    break
                            except json.JSONDecodeError:
                                continue
                    
                    print()  # –ù–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –ø–æ—Å–ª–µ –≤—ã–≤–æ–¥–∞
                    print(f"‚úÖ –ü–æ—Ç–æ–∫–æ–≤–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞!")
                    print(f"   –ü–æ–ª—É—á–µ–Ω–æ —á–∞–Ω–∫–æ–≤: {len(chunks)}")
                    return True
                else:
                    error_text = await response.aread()
                    print(f"‚ùå –û—à–∏–±–∫–∞: {response.status_code}")
                    print(f"   {error_text.decode()[:200]}")
                    return False
                    
    except httpx.TimeoutException:
        print(f"‚ùå –¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –ø–æ—Ç–æ–∫–æ–≤–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏")
        return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
        return False


async def check_ollama_health(base_url: str = "http://localhost:11434") -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–µ—Ä–∞ (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω endpoint)"""
    try:
        async with httpx.AsyncClient(timeout=5.0) as client:
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ endpoints
            endpoints = ["/", "/api/version", "/api/tags"]
            
            for endpoint in endpoints:
                try:
                    response = await client.get(f"{base_url}{endpoint}")
                    if response.status_code == 200:
                        print(f"‚úÖ Health check —É—Å–ø–µ—à–µ–Ω ({endpoint})")
                        return True
                except:
                    continue
            
            return False
    except:
        return False


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("=" * 60)
    print("–ü—Ä–æ–≤–µ—Ä–∫–∞ Ollama —Å–µ—Ä–≤–µ—Ä–∞ –Ω–∞ localhost")
    print("=" * 60)
    
    base_url = "http://localhost:11434"
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–µ—Ä–∞
    server_available = await check_ollama_server(base_url)
    
    if not server_available:
        print(f"\nüí° –ö–∞–∫ –∑–∞–ø—É—Å—Ç–∏—Ç—å Ollama:")
        print(f"   1. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Ollama: https://ollama.ai")
        print(f"   2. –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–µ—Ä–≤–µ—Ä: ollama serve")
        print(f"   3. –ò–ª–∏ –ø—Ä–æ—Å—Ç–æ: ollama (–∑–∞–ø—É—Å–∫–∞–µ—Ç —Å–µ—Ä–≤–µ—Ä –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)")
        print(f"\nüí° –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –ø–æ—Ä—Ç—ã:")
        print(f"   –ï—Å–ª–∏ Ollama –Ω–∞ –¥—Ä—É–≥–æ–º –ø–æ—Ä—Ç—É, —É–∫–∞–∂–∏—Ç–µ:")
        print(f"   OLLAMA_BASE_URL=http://localhost:PORT")
        return
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è
    await check_ollama_health(base_url)
    
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ç–µ—Å—Ç–∞
    try:
        async with httpx.AsyncClient(timeout=5.0) as client:
            response = await client.get(f"{base_url}/api/tags")
            if response.status_code == 200:
                data = response.json()
                models = data.get("models", [])
                if models:
                    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é –º–æ–¥–µ–ª—å
                    test_model = models[0].get("name", "llama2")
                    print(f"\nüß™ –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å '{test_model}' –¥–ª—è —Ç–µ—Å—Ç–æ–≤...")
                    
                    # –¢–µ—Å—Ç –æ–±—ã—á–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
                    await test_ollama_generate(base_url, test_model)
                    
                    # –¢–µ—Å—Ç –ø–æ—Ç–æ–∫–æ–≤–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –º–æ–∂–µ—Ç –±—ã—Ç—å –º–µ–¥–ª–µ–Ω–Ω—ã–º)
                    # await test_ollama_stream(base_url, test_model)
    
    except Exception as e:
        print(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π: {e}")
    
    print("\n" + "=" * 60)
    print("‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    print("=" * 60)


if __name__ == "__main__":
    asyncio.run(main())

