#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ Ollama —Å –ø—Ä–æ–µ–∫—Ç–æ–º —á–µ—Ä–µ–∑ CustomProvider
"""
import asyncio
from core.llm.custom_provider import CustomProvider
from core.llm.base import LLMMessage
from config import settings


async def test_ollama_via_custom_provider():
    """–¢–µ—Å—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è Ollama —á–µ—Ä–µ–∑ CustomProvider"""
    print("=" * 60)
    print("–¢–µ—Å—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ Ollama —Å –ø—Ä–æ–µ–∫—Ç–æ–º")
    print("=" * 60)
    
    # Ollama –∏—Å–ø–æ–ª—å–∑—É–µ—Ç OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π API –Ω–∞ –ø–æ—Ä—Ç—É 11434
    # –ù–æ endpoint –Ω–µ–º–Ω–æ–≥–æ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è: /api/generate –≤–º–µ—Å—Ç–æ /chat/completions
    # –î–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å /v1/chat/completions –µ—Å–ª–∏ Ollama –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á–µ—Ä–µ–∑ CustomProvider —Å –±–∞–∑–æ–≤—ã–º URL Ollama
    ollama_url = "http://localhost:11434/v1"  # –ü–æ–ø—Ä–æ–±—É–µ–º —Å /v1
    
    print(f"\nüîç –¢–µ—Å—Ç–∏—Ä—É—é Ollama —á–µ—Ä–µ–∑ CustomProvider...")
    print(f"   URL: {ollama_url}")
    
    try:
        provider = CustomProvider(
            base_url=ollama_url,
            api_key="ollama",  # Ollama –Ω–µ —Ç—Ä–µ–±—É–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–π –∫–ª—é—á
            model="gpt-oss:120b-cloud"  # –ú–æ–¥–µ–ª—å –∏–∑ –ø—Ä–æ–≤–µ—Ä–∫–∏
        )
        
        messages = [
            LLMMessage(role="system", content="You are a helpful assistant."),
            LLMMessage(role="user", content="Say 'Hello from Ollama!' in one sentence.")
        ]
        
        print(f"\nüí¨ –û—Ç–ø—Ä–∞–≤–ª—è—é –∑–∞–ø—Ä–æ—Å...")
        response = await provider.generate(messages, temperature=0.7)
        
        print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ!")
        print(f"   –û—Ç–≤–µ—Ç: {response.content}")
        print(f"   –ú–æ–¥–µ–ª—å: {response.model}")
        
        await provider.close()
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        print(f"\nüí° Ollama –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –¥—Ä—É–≥–æ–π API —Ñ–æ—Ä–º–∞—Ç.")
        print(f"   –ù—É–∂–Ω–æ —Å–æ–∑–¥–∞—Ç—å –æ—Ç–¥–µ–ª—å–Ω—ã–π OllamaProvider –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä—è–º–æ–π API.")
        return False


async def test_ollama_direct_api():
    """–ü—Ä—è–º–æ–π —Ç–µ—Å—Ç Ollama API"""
    import httpx
    import json
    
    print(f"\nüîç –¢–µ—Å—Ç–∏—Ä—É—é –ø—Ä—è–º–æ–π Ollama API...")
    
    try:
        async with httpx.AsyncClient(timeout=30.0) as client:
            # Ollama –∏—Å–ø–æ–ª—å–∑—É–µ—Ç /api/generate, –Ω–µ /chat/completions
            response = await client.post(
                "http://localhost:11434/api/generate",
                json={
                    "model": "gpt-oss:120b-cloud",
                    "prompt": "Say 'Hello from Ollama!' in one sentence.",
                    "stream": False
                }
            )
            
            if response.status_code == 200:
                data = response.json()
                print(f"‚úÖ –ü—Ä—è–º–æ–π API —Ä–∞–±–æ—Ç–∞–µ—Ç!")
                print(f"   –û—Ç–≤–µ—Ç: {data.get('response', '')}")
                print(f"   –¢–æ–∫–µ–Ω–æ–≤: {data.get('eval_count', 0)}")
                return True
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞: {response.status_code}")
                print(f"   {response.text[:200]}")
                return False
                
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        return False


async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    # –°–Ω–∞—á–∞–ª–∞ —Ç–µ—Å—Ç –ø—Ä—è–º–æ–≥–æ API
    direct_ok = await test_ollama_direct_api()
    
    # –ó–∞—Ç–µ–º —Ç–µ—Å—Ç —á–µ—Ä–µ–∑ CustomProvider
    if direct_ok:
        await test_ollama_via_custom_provider()
    
    print("\n" + "=" * 60)
    print("üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
    print("=" * 60)
    print("1. Ollama —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ http://localhost:11434")
    print("2. API —Ñ–æ—Ä–º–∞—Ç –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç OpenAI:")
    print("   - Ollama: /api/generate")
    print("   - OpenAI: /v1/chat/completions")
    print("3. –î–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –º–æ–∂–Ω–æ:")
    print("   a) –°–æ–∑–¥–∞—Ç—å OllamaProvider (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)")
    print("   b) –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å CustomProvider —Å –∞–¥–∞–ø—Ç–∞—Ü–∏–µ–π")
    print("   c) –ù–∞—Å—Ç—Ä–æ–∏—Ç—å Ollama proxy –¥–ª—è OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º–æ–≥–æ API")


if __name__ == "__main__":
    asyncio.run(main())

